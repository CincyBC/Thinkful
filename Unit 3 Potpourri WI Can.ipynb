{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "main_start = datetime.now()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension   ...    worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871   ...            17.33           184.60      2019.0   \n",
       "1                 0.05667   ...            23.41           158.80      1956.0   \n",
       "2                 0.05999   ...            25.53           152.50      1709.0   \n",
       "3                 0.09744   ...            26.50            98.87       567.7   \n",
       "4                 0.05883   ...            16.67           152.20      1575.0   \n",
       "5                 0.07613   ...            23.75           103.40       741.6   \n",
       "6                 0.05742   ...            27.66           153.20      1606.0   \n",
       "7                 0.07451   ...            28.14           110.60       897.0   \n",
       "8                 0.07389   ...            30.73           106.20       739.3   \n",
       "9                 0.08243   ...            40.68            97.65       711.4   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "5            0.1791             0.5249           0.5355                0.1741   \n",
       "6            0.1442             0.2576           0.3784                0.1932   \n",
       "7            0.1654             0.3682           0.2678                0.1556   \n",
       "8            0.1703             0.5401           0.5390                0.2060   \n",
       "9            0.1853             1.0580           1.1050                0.2210   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "5          0.3985                  0.12440     0.0  \n",
       "6          0.3063                  0.08368     0.0  \n",
       "7          0.3196                  0.11510     0.0  \n",
       "8          0.4378                  0.10720     0.0  \n",
       "9          0.4366                  0.20750     0.0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.c_[raw_data.data, raw_data.target]\n",
    "columns = np.append(raw_data.feature_names, [\"target\"])\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                float64\n",
       "mean texture               float64\n",
       "mean perimeter             float64\n",
       "mean area                  float64\n",
       "mean smoothness            float64\n",
       "mean compactness           float64\n",
       "mean concavity             float64\n",
       "mean concave points        float64\n",
       "mean symmetry              float64\n",
       "mean fractal dimension     float64\n",
       "radius error               float64\n",
       "texture error              float64\n",
       "perimeter error            float64\n",
       "area error                 float64\n",
       "smoothness error           float64\n",
       "compactness error          float64\n",
       "concavity error            float64\n",
       "concave points error       float64\n",
       "symmetry error             float64\n",
       "fractal dimension error    float64\n",
       "worst radius               float64\n",
       "worst texture              float64\n",
       "worst perimeter            float64\n",
       "worst area                 float64\n",
       "worst smoothness           float64\n",
       "worst compactness          float64\n",
       "worst concavity            float64\n",
       "worst concave points       float64\n",
       "worst symmetry             float64\n",
       "worst fractal dimension    float64\n",
       "target                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    357\n",
       "0.0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benign = 1.0, Malignant = 0.0\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    236\n",
      "0.0    145\n",
      "Name: target, dtype: int64\n",
      "\n",
      "\n",
      "1.0    121\n",
      "0.0     67\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['target'], 1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print(y_train.value_counts())\n",
    "print('\\n')\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up our first X using PCA\n",
    "pca = PCA(n_components=6)\n",
    "X_std_pca = pca.fit_transform(X_train)\n",
    "X1 = pd.DataFrame(X_std_pca)\n",
    "\n",
    "#Now for the Test\n",
    "pca = PCA(n_components=6)\n",
    "X_std_pca = pca.fit_transform(X_test)\n",
    "X1_test = pd.DataFrame(X_std_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Features  Ranking  Support\n",
      "0               mean radius        1     True\n",
      "21            worst texture        1     True\n",
      "11            texture error        1     True\n",
      "13               area error        1     True\n",
      "26          worst concavity        1     True\n",
      "1              mean texture        1     True\n",
      "2            mean perimeter        1     True\n",
      "22          worst perimeter        2    False\n",
      "3                 mean area        3    False\n",
      "23               worst area        4    False\n",
      "25        worst compactness        5    False\n",
      "18           symmetry error        6    False\n",
      "17     concave points error        7    False\n",
      "16          concavity error        8    False\n",
      "7       mean concave points        9    False\n",
      "6            mean concavity       10    False\n",
      "5          mean compactness       11    False\n",
      "4           mean smoothness       12    False\n",
      "19  fractal dimension error       13    False\n",
      "8             mean symmetry       14    False\n",
      "20             worst radius       15    False\n",
      "9    mean fractal dimension       16    False\n",
      "24         worst smoothness       17    False\n",
      "10             radius error       18    False\n",
      "27     worst concave points       19    False\n",
      "12          perimeter error       20    False\n",
      "28           worst symmetry       21    False\n",
      "29  worst fractal dimension       22    False\n",
      "15        compactness error       23    False\n",
      "14         smoothness error       24    False\n",
      "It took the following time to complete this task: 0:00:27.455625\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "#Use Lasso/RFE with Cross Validation to get the best features for our second X\n",
    "lr = LogisticRegression(C=1, penalty='l1')\n",
    "\n",
    "#Set up our X,y\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "#Set up our Recursive Feature Elimination\n",
    "rfe = RFECV(lr,cv=5) \n",
    "fit = rfe.fit(X,y)\n",
    "result_RFE = pd.DataFrame(list(zip(X.head(0), rfe.ranking_, rfe.support_)),\n",
    "                          columns=['Features','Ranking','Support'] ) \n",
    "print(result_RFE.sort_values('Ranking'))\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_values = result_RFE[result_RFE.Support == True]\n",
    "feature_list = []\n",
    "for g in true_values['Features']:\n",
    "    feature_list.append(g)\n",
    "X2 = X_train[feature_list]\n",
    "X2_test = X_test[feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean radius', 0.037276174461743777)\n",
      "('mean texture', 0.013247063371622285)\n",
      "('mean perimeter', 0.048953902560322587)\n",
      "('mean area', 0.036048174413680072)\n",
      "('mean smoothness', 0.0055517841731483651)\n",
      "('mean compactness', 0.014192584400808787)\n",
      "('mean concavity', 0.067550378387953885)\n",
      "('mean concave points', 0.12839577373170524)\n",
      "('mean symmetry', 0.0037155100099138597)\n",
      "('mean fractal dimension', 0.0047218697364518952)\n",
      "('radius error', 0.017646293451140868)\n",
      "('texture error', 0.0043445402294177982)\n",
      "('perimeter error', 0.012159365770607826)\n",
      "('area error', 0.027468926014620119)\n",
      "('smoothness error', 0.0052989711277984484)\n",
      "('compactness error', 0.0047002931921151583)\n",
      "('concavity error', 0.0065176802329209981)\n",
      "('concave points error', 0.0041956683448790702)\n",
      "('symmetry error', 0.0049424005406347431)\n",
      "('fractal dimension error', 0.0056106882339846467)\n",
      "('worst radius', 0.091631584002856564)\n",
      "('worst texture', 0.017915987085504213)\n",
      "('worst perimeter', 0.11349576554941122)\n",
      "('worst area', 0.091557759567123878)\n",
      "('worst smoothness', 0.010928055908355523)\n",
      "('worst compactness', 0.01846140772889383)\n",
      "('worst concavity', 0.041563427206660411)\n",
      "('worst concave points', 0.1408979742046654)\n",
      "('worst symmetry', 0.014220619512996949)\n",
      "('worst fractal dimension', 0.0067893768480616007)\n",
      "It took the following time to complete this task: 0:00:02.024089\n"
     ]
    }
   ],
   "source": [
    "# Let's use Random Forest to select features down to 30.\n",
    "start = datetime.now()\n",
    "X = X_train\n",
    "y = y_train\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "df2 = X.columns.get_values()\n",
    "feat_labels = df2.tolist()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X, y)\n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "for feature in zip(X, clf.feature_importances_):\n",
    "    print(feature)\n",
    "\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean concavity\n",
      "mean concave points\n",
      "worst radius\n",
      "worst perimeter\n",
      "worst area\n",
      "worst concave points\n",
      "Number of features in this list: 6\n",
      "It took the following time to complete this task: 0:00:02.016806\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "sfm = SelectFromModel(clf, threshold=0.05)\n",
    "rfcfeature_list =[]\n",
    "# Train the selector\n",
    "sfm.fit(X, y)\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    rfcfeature_list.append(feat_labels[feature_list_index])\n",
    "    print(feat_labels[feature_list_index])\n",
    "X3 = X_train[rfcfeature_list]\n",
    "X3_test = X_test[rfcfeature_list]\n",
    "    \n",
    "print('Number of features in this list: {}'.format(len(rfcfeature_list)))\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a list to store our results for a comparison at the end\n",
    "results = pd.DataFrame(index=range(21))\n",
    "results['Model'] = ['Logistic Regression',\n",
    "                    'Logistic Regression',\n",
    "                    'Logistic Regression',\n",
    "                    'Lasso Regression',\n",
    "                    'Lasso Regression',\n",
    "                    'Lasso Regression',\n",
    "                    'Ridge Regression',\n",
    "                    'Ridge Regression',\n",
    "                    'Ridge Regression',\n",
    "                    'KNN', 'KNN', 'KNN',\n",
    "                    'SVC', 'SVC', 'SVC',\n",
    "                    'Random Forest',\n",
    "                    'Random Forest',\n",
    "                    'Random Forest',\n",
    "                    'Gradient Booster',\n",
    "                    'Gradient Booster',\n",
    "                    'Gradient Booster',\n",
    "                    ]\n",
    "results['Feature Selection'] = ['PCA', 'RFECV', 'Random Forest',\n",
    "                               'PCA', 'RFECV', 'Random Forest',\n",
    "                               'PCA', 'RFECV', 'Random Forest',\n",
    "                               'PCA', 'RFECV', 'Random Forest',\n",
    "                               'PCA', 'RFECV', 'Random Forest',\n",
    "                               'PCA', 'RFECV', 'Random Forest',\n",
    "                               'PCA', 'RFECV', 'Random Forest']\n",
    "\n",
    "\n",
    "Train_Score = []\n",
    "Test_Score = []\n",
    "Cross_Validation = []\n",
    "fold1 = []\n",
    "fold2 = []\n",
    "fold3 = []\n",
    "fold4 = []\n",
    "fold5 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared for the training set with PCA:\n",
      "0.94750656168\n",
      "\n",
      "R-squared for the test set with PCA:\n",
      "0.994680851064\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.93506494  0.93421053  0.97368421  0.92105263  0.92105263]\n",
      "\n",
      "R-squared for the training set with RFECV generated features:\n",
      "0.971128608924\n",
      "\n",
      "R-squared for the test set with RFECV generated features:\n",
      "0.968085106383\n",
      "\n",
      "Cross Validation Score with 5 folds with RFECV generated features:\n",
      "[ 0.97402597  0.96052632  0.96052632  0.97368421  0.92105263]\n",
      "\n",
      "R-squared for the training set with Random Forest generated features:\n",
      "0.944881889764\n",
      "\n",
      "R-squared for the test set with Random Forest generated features:\n",
      "0.984042553191\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.94805195  0.93421053  0.93421053  0.93421053  0.92105263]\n",
      "It took the following time to complete this task: 0:00:00.083768\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "#Let's compare our features in various models starting with Logistic Regression\n",
    "lr = LogisticRegression(C=9e9)\n",
    "#Fit the model\n",
    "lr.fit(X1, y)\n",
    "score1 = lr.score(X1, y)\n",
    "Train_Score.append(score1)\n",
    "lr.fit(X1_test, y_test)\n",
    "score2 = lr.score(X1_test, y_test)\n",
    "Test_Score.append(score2)\n",
    "lr.fit(X2, y)\n",
    "score3 = lr.score(X2, y)\n",
    "Train_Score.append(score3)\n",
    "lr.fit(X2_test, y_test)\n",
    "score4 = lr.score(X2_test, y_test)\n",
    "Test_Score.append(score4)\n",
    "lr.fit(X3, y)\n",
    "score5 = lr.score(X3, y)\n",
    "Train_Score.append(score5)\n",
    "lr.fit(X3_test, y_test)\n",
    "score6 = lr.score(X3_test, y_test)\n",
    "Test_Score.append(score6)\n",
    "\n",
    "# Inspect the results.\n",
    "print('\\nR-squared for the training set with PCA:')\n",
    "print(score1)\n",
    "print('\\nR-squared for the test set with PCA:')\n",
    "print(score2)\n",
    "Cross_Validation0 = cross_val_score(lr, X1, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with RFECV generated features:')\n",
    "print(score3)\n",
    "print('\\nR-squared for the test set with RFECV generated features:')\n",
    "print(score4)\n",
    "Cross_Validation0 = cross_val_score(lr, X2, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with RFECV generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with Random Forest generated features:')\n",
    "print(score5)\n",
    "print('\\nR-squared for the test set with Random Forest generated features:')\n",
    "print(score6)\n",
    "Cross_Validation0 = cross_val_score(lr, X3, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared for the training set with PCA:\n",
      "0.94750656168\n",
      "\n",
      "R-squared for the test set with PCA:\n",
      "0.978723404255\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.94805195  0.93421053  0.97368421  0.93421053  0.90789474]\n",
      "\n",
      "R-squared for the training set with RFECV generated features:\n",
      "0.96062992126\n",
      "\n",
      "R-squared for the test set with RFECV generated features:\n",
      "0.962765957447\n",
      "\n",
      "Cross Validation Score with 5 folds with RFECV generated features:\n",
      "[ 0.93506494  0.97368421  0.98684211  0.97368421  0.88157895]\n",
      "\n",
      "R-squared for the training set with Random Forest generated features:\n",
      "0.926509186352\n",
      "\n",
      "R-squared for the test set with Random Forest generated features:\n",
      "0.952127659574\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.90909091  0.90789474  0.92105263  0.88157895  0.88157895]\n",
      "It took the following time to complete this task: 0:00:00.783735\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "#Let's pop those into the model\n",
    "lr = LogisticRegression(C=1, penalty='l1')\n",
    "#Fit the model\n",
    "lr.fit(X1, y)\n",
    "score1 = lr.score(X1, y)\n",
    "Train_Score.append(score1)\n",
    "lr.fit(X1_test, y_test)\n",
    "score2 = lr.score(X1_test, y_test)\n",
    "Test_Score.append(score2)\n",
    "lr.fit(X2, y)\n",
    "score3 = lr.score(X2, y)\n",
    "Train_Score.append(score3)\n",
    "lr.fit(X2_test, y_test)\n",
    "score4 = lr.score(X2_test, y_test)\n",
    "Test_Score.append(score4)\n",
    "lr.fit(X3, y)\n",
    "score5 = lr.score(X3, y)\n",
    "Train_Score.append(score5)\n",
    "lr.fit(X3_test, y_test)\n",
    "score6 = lr.score(X3_test, y_test)\n",
    "Test_Score.append(score6)\n",
    "\n",
    "# Inspect the results.\n",
    "print('\\nR-squared for the training set with PCA:')\n",
    "print(score1)\n",
    "print('\\nR-squared for the test set with PCA:')\n",
    "print(score2)\n",
    "Cross_Validation0 = cross_val_score(lr, X1, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with RFECV generated features:')\n",
    "print(score3)\n",
    "print('\\nR-squared for the test set with RFECV generated features:')\n",
    "print(score4)\n",
    "Cross_Validation0 = cross_val_score(lr, X2, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with RFECV generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with Random Forest generated features:')\n",
    "print(score5)\n",
    "print('\\nR-squared for the test set with Random Forest generated features:')\n",
    "print(score6)\n",
    "Cross_Validation0 = cross_val_score(lr, X3, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared for the training set with PCA:\n",
      "0.950131233596\n",
      "\n",
      "R-squared for the test set with PCA:\n",
      "0.984042553191\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.93506494  0.93421053  0.97368421  0.92105263  0.92105263]\n",
      "\n",
      "R-squared for the training set with RFECV generated features:\n",
      "0.944881889764\n",
      "\n",
      "R-squared for the test set with RFECV generated features:\n",
      "0.946808510638\n",
      "\n",
      "Cross Validation Score with 5 folds with RFECV generated features:\n",
      "[ 0.90909091  0.97368421  0.98684211  0.94736842  0.90789474]\n",
      "\n",
      "R-squared for the training set with Random Forest generated features:\n",
      "0.910761154856\n",
      "\n",
      "R-squared for the test set with Random Forest generated features:\n",
      "0.952127659574\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.90909091  0.92105263  0.90789474  0.88157895  0.89473684]\n",
      "It took the following time to complete this task: 0:00:00.063022\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "#Let's pop those into the model\n",
    "lr = LogisticRegression(C=1, penalty='l2')\n",
    "#Fit the model\n",
    "lr.fit(X1, y)\n",
    "score1 = lr.score(X1, y)\n",
    "Train_Score.append(score1)\n",
    "lr.fit(X1_test, y_test)\n",
    "score2 = lr.score(X1_test, y_test)\n",
    "Test_Score.append(score2)\n",
    "lr.fit(X2, y)\n",
    "score3 = lr.score(X2, y)\n",
    "Train_Score.append(score3)\n",
    "lr.fit(X2_test, y_test)\n",
    "score4 = lr.score(X2_test, y_test)\n",
    "Test_Score.append(score4)\n",
    "lr.fit(X3, y)\n",
    "score5 = lr.score(X3, y)\n",
    "Train_Score.append(score5)\n",
    "lr.fit(X3_test, y_test)\n",
    "score6 = lr.score(X3_test, y_test)\n",
    "Test_Score.append(score6)\n",
    "\n",
    "# Inspect the results.\n",
    "print('\\nR-squared for the training set with PCA:')\n",
    "print(score1)\n",
    "print('\\nR-squared for the test set with PCA:')\n",
    "print(score2)\n",
    "Cross_Validation0 = cross_val_score(lr, X1, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with RFECV generated features:')\n",
    "print(score3)\n",
    "print('\\nR-squared for the test set with RFECV generated features:')\n",
    "print(score4)\n",
    "Cross_Validation0 = cross_val_score(lr, X2, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with RFECV generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with Random Forest generated features:')\n",
    "print(score5)\n",
    "print('\\nR-squared for the test set with Random Forest generated features:')\n",
    "print(score6)\n",
    "Cross_Validation0 = cross_val_score(lr, X3, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared for the training set with PCA:\n",
      "0.92125984252\n",
      "\n",
      "R-squared for the test set with PCA:\n",
      "0.973404255319\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.92207792  0.92105263  0.93421053  0.89473684  0.92105263]\n",
      "\n",
      "R-squared for the training set with RFECV generated features:\n",
      "0.926509186352\n",
      "\n",
      "R-squared for the test set with RFECV generated features:\n",
      "0.93085106383\n",
      "\n",
      "Cross Validation Score with 5 folds with RFECV generated features:\n",
      "[ 0.8961039   0.89473684  0.97368421  0.88157895  0.88157895]\n",
      "\n",
      "R-squared for the training set with Random Forest generated features:\n",
      "0.913385826772\n",
      "\n",
      "R-squared for the test set with Random Forest generated features:\n",
      "0.952127659574\n",
      "\n",
      "Cross Validation Score with 5 folds with Random Forest generated features:\n",
      "[ 0.92207792  0.90789474  0.89473684  0.89473684  0.88157895]\n",
      "It took the following time to complete this task: 0:00:00.076210\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "neighbors = KNeighborsClassifier(n_neighbors=5)\n",
    "#Fit the model\n",
    "neighbors.fit(X1, y)\n",
    "score1 = neighbors.score(X1, y)\n",
    "Train_Score.append(score1)\n",
    "neighbors.fit(X1_test, y_test)\n",
    "score2 = neighbors.score(X1_test, y_test)\n",
    "Test_Score.append(score2)\n",
    "neighbors.fit(X2, y)\n",
    "score3 = neighbors.score(X2, y)\n",
    "Train_Score.append(score3)\n",
    "neighbors.fit(X2_test, y_test)\n",
    "score4 = neighbors.score(X2_test, y_test)\n",
    "Test_Score.append(score4)\n",
    "neighbors.fit(X3, y)\n",
    "score5 = neighbors.score(X3, y)\n",
    "Train_Score.append(score5)\n",
    "neighbors.fit(X3_test, y_test)\n",
    "score6 = neighbors.score(X3_test, y_test)\n",
    "Test_Score.append(score6)\n",
    "\n",
    "# Inspect the results.\n",
    "print('\\nR-squared for the training set with PCA:')\n",
    "print(score1)\n",
    "print('\\nR-squared for the test set with PCA:')\n",
    "print(score2)\n",
    "Cross_Validation0 = cross_val_score(neighbors, X1, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with RFECV generated features:')\n",
    "print(score3)\n",
    "print('\\nR-squared for the test set with RFECV generated features:')\n",
    "print(score4)\n",
    "Cross_Validation0 = cross_val_score(neighbors, X2, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with RFECV generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with Random Forest generated features:')\n",
    "print(score5)\n",
    "print('\\nR-squared for the test set with Random Forest generated features:')\n",
    "print(score6)\n",
    "Cross_Validation0 = cross_val_score(neighbors, X3, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with Random Forest generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared for the training set with PCA:\n",
      "1.0\n",
      "\n",
      "R-squared for the test set with PCA:\n",
      "1.0\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.62337662  0.61842105  0.61842105  0.61842105  0.61842105]\n",
      "\n",
      "R-squared for the training set with RFECV generated features:\n",
      "0.994750656168\n",
      "\n",
      "R-squared for the test set with RFECV generated features:\n",
      "1.0\n",
      "\n",
      "Cross Validation Score with 5 folds with RFECV generated features:\n",
      "[ 0.63636364  0.61842105  0.64473684  0.64473684  0.64473684]\n",
      "\n",
      "R-squared for the training set with Random Forest generated features:\n",
      "0.992125984252\n",
      "\n",
      "R-squared for the test set with Random Forest generated features:\n",
      "0.994680851064\n",
      "\n",
      "Cross Validation Score with 5 folds with Random Forest generated features:\n",
      "[ 0.64935065  0.64473684  0.67105263  0.64473684  0.64473684]\n",
      "It took the following time to complete this task: 0:00:00.163864\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "#Now let's model with SVM\n",
    "svc = SVC()\n",
    "#Fit the model\n",
    "svc.fit(X1, y)\n",
    "score1 = svc.score(X1, y)\n",
    "Train_Score.append(score1)\n",
    "svc.fit(X1_test, y_test)\n",
    "score2 = svc.score(X1_test, y_test)\n",
    "Test_Score.append(score2)\n",
    "svc.fit(X2, y)\n",
    "score3 = svc.score(X2, y)\n",
    "Train_Score.append(score3)\n",
    "svc.fit(X2_test, y_test)\n",
    "score4 = svc.score(X2_test, y_test)\n",
    "Test_Score.append(score4)\n",
    "svc.fit(X3, y)\n",
    "score5 = svc.score(X3, y)\n",
    "Train_Score.append(score5)\n",
    "svc.fit(X3_test, y_test)\n",
    "score6 = svc.score(X3_test, y_test)\n",
    "Test_Score.append(score6)\n",
    "\n",
    "# Inspect the results.\n",
    "print('\\nR-squared for the training set with PCA:')\n",
    "print(score1)\n",
    "print('\\nR-squared for the test set with PCA:')\n",
    "print(score2)\n",
    "Cross_Validation0 = cross_val_score(svc, X1, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with RFECV generated features:')\n",
    "print(score3)\n",
    "print('\\nR-squared for the test set with RFECV generated features:')\n",
    "print(score4)\n",
    "Cross_Validation0 = cross_val_score(svc, X2, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with RFECV generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with Random Forest generated features:')\n",
    "print(score5)\n",
    "print('\\nR-squared for the test set with Random Forest generated features:')\n",
    "print(score6)\n",
    "Cross_Validation0 = cross_val_score(svc, X3, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with Random Forest generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared for the training set with PCA:\n",
      "1.0\n",
      "\n",
      "R-squared for the test set with PCA:\n",
      "1.0\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.93506494  0.90789474  0.90789474  0.92105263  0.92105263]\n",
      "\n",
      "R-squared for the training set with RFECV generated features:\n",
      "0.994750656168\n",
      "\n",
      "R-squared for the test set with RFECV generated features:\n",
      "1.0\n",
      "\n",
      "Cross Validation Score with 5 folds with RFECV generated features:\n",
      "[ 0.96103896  0.93421053  0.96052632  0.92105263  0.94736842]\n",
      "\n",
      "R-squared for the training set with Random Forest generated features:\n",
      "0.992125984252\n",
      "\n",
      "R-squared for the test set with Random Forest generated features:\n",
      "1.0\n",
      "\n",
      "Cross Validation Score with 5 folds with Random Forest generated features:\n",
      "[ 0.94805195  0.94736842  0.92105263  0.93421053  0.94736842]\n",
      "It took the following time to complete this task: 0:00:00.373847\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "#Now let's model with Random Forest\n",
    "rfc = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                      min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                                      max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                                      bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, \n",
    "                                      warm_start=False, class_weight=None)\n",
    "\n",
    "#Fit the model\n",
    "rfc.fit(X1, y)\n",
    "score1 = rfc.score(X1, y)\n",
    "Train_Score.append(score1)\n",
    "rfc.fit(X1_test, y_test)\n",
    "score2 = rfc.score(X1_test, y_test)\n",
    "Test_Score.append(score2)\n",
    "rfc.fit(X2, y)\n",
    "score3 = rfc.score(X2, y)\n",
    "Train_Score.append(score3)\n",
    "rfc.fit(X2_test, y_test)\n",
    "score4 = rfc.score(X2_test, y_test)\n",
    "Test_Score.append(score4)\n",
    "rfc.fit(X3, y)\n",
    "score5 = rfc.score(X3, y)\n",
    "Train_Score.append(score5)\n",
    "rfc.fit(X3_test, y_test)\n",
    "score6 = rfc.score(X3_test, y_test)\n",
    "Test_Score.append(score6)\n",
    "\n",
    "# Inspect the results.\n",
    "print('\\nR-squared for the training set with PCA:')\n",
    "print(score1)\n",
    "print('\\nR-squared for the test set with PCA:')\n",
    "print(score2)\n",
    "Cross_Validation0 = cross_val_score(rfc, X1, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with RFECV generated features:')\n",
    "print(score3)\n",
    "print('\\nR-squared for the test set with RFECV generated features:')\n",
    "print(score4)\n",
    "Cross_Validation0 = cross_val_score(rfc, X2, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with RFECV generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with Random Forest generated features:')\n",
    "print(score5)\n",
    "print('\\nR-squared for the test set with Random Forest generated features:')\n",
    "print(score6)\n",
    "Cross_Validation0 = cross_val_score(rfc, X3, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with Random Forest generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared for the training set with PCA:\n",
      "1.0\n",
      "\n",
      "R-squared for the test set with PCA:\n",
      "1.0\n",
      "\n",
      "Cross Validation Score with 5 folds with PCA:\n",
      "[ 0.98701299  0.93421053  0.94736842  0.94736842  0.89473684]\n",
      "\n",
      "R-squared for the training set with RFECV generated features:\n",
      "1.0\n",
      "\n",
      "R-squared for the test set with RFECV generated features:\n",
      "1.0\n",
      "\n",
      "Cross Validation Score with 5 folds with RFECV generated features:\n",
      "[ 0.94805195  0.93421053  0.94736842  0.96052632  0.92105263]\n",
      "\n",
      "R-squared for the training set with Random Forest generated features:\n",
      "1.0\n",
      "\n",
      "R-squared for the test set with Random Forest generated features:\n",
      "1.0\n",
      "\n",
      "Cross Validation Score with 5 folds with Random Forest generated features:\n",
      "[ 0.94805195  0.92105263  0.92105263  0.93421053  0.96052632]\n",
      "It took the following time to complete this task: 0:00:09.417496\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "#Now let's model with Gradient Boosting\n",
    "clf = GradientBoostingClassifier(loss='exponential', learning_rate=0.1, n_estimators=1000, subsample=0.75, \n",
    "                                          criterion='friedman_mse', min_samples_split=4, min_samples_leaf=1, \n",
    "                                          min_weight_fraction_leaf=0.0, max_depth=5, min_impurity_decrease=0.0, \n",
    "                                          min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
    "                                          verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "\n",
    "#Fit the model\n",
    "clf.fit(X1, y)\n",
    "score1 = clf.score(X1, y)\n",
    "Train_Score.append(score1)\n",
    "clf.fit(X1_test, y_test)\n",
    "score2 = clf.score(X1_test, y_test)\n",
    "Test_Score.append(score2)\n",
    "clf.fit(X2, y)\n",
    "score3 = clf.score(X2, y)\n",
    "Train_Score.append(score3)\n",
    "clf.fit(X2_test, y_test)\n",
    "score4 = clf.score(X2_test, y_test)\n",
    "Test_Score.append(score4)\n",
    "clf.fit(X3, y)\n",
    "score5 = clf.score(X3, y)\n",
    "Train_Score.append(score5)\n",
    "clf.fit(X3_test, y_test)\n",
    "score6 = clf.score(X3_test, y_test)\n",
    "Test_Score.append(score6)\n",
    "\n",
    "# Inspect the results.\n",
    "print('\\nR-squared for the training set with PCA:')\n",
    "print(score1)\n",
    "print('\\nR-squared for the test set with PCA:')\n",
    "print(score2)\n",
    "Cross_Validation0 = cross_val_score(clf, X1, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with PCA:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with RFECV generated features:')\n",
    "print(score3)\n",
    "print('\\nR-squared for the test set with RFECV generated features:')\n",
    "print(score4)\n",
    "Cross_Validation0 = cross_val_score(clf, X2, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with RFECV generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('\\nR-squared for the training set with Random Forest generated features:')\n",
    "print(score5)\n",
    "print('\\nR-squared for the test set with Random Forest generated features:')\n",
    "print(score6)\n",
    "Cross_Validation0 = cross_val_score(clf, X3, y, cv=5)\n",
    "print('\\nCross Validation Score with 5 folds with Random Forest generated features:\\n{}'.format(Cross_Validation0))\n",
    "Cross_Validation.append(Cross_Validation0)\n",
    "fold1.append(Cross_Validation0[0])\n",
    "fold2.append(Cross_Validation0[1])\n",
    "fold3.append(Cross_Validation0[2])\n",
    "fold4.append(Cross_Validation0[3])\n",
    "fold5.append(Cross_Validation0[4])\n",
    "print('It took the following time to complete this task:', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature Selection</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>CV Fold 1</th>\n",
       "      <th>CV Fold 2</th>\n",
       "      <th>CV Fold 3</th>\n",
       "      <th>CV Fold 4</th>\n",
       "      <th>CV Fold 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>PCA</td>\n",
       "      <td>0.947507</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>0.971129</td>\n",
       "      <td>0.968085</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>PCA</td>\n",
       "      <td>0.947507</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.907895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.962766</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.926509</td>\n",
       "      <td>0.952128</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>PCA</td>\n",
       "      <td>0.950131</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.946809</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.907895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.910761</td>\n",
       "      <td>0.952128</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>PCA</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>0.973404</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNN</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>0.926509</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.913386</td>\n",
       "      <td>0.952128</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC</td>\n",
       "      <td>PCA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.618421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>PCA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>0.994751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gradient Booster</td>\n",
       "      <td>PCA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Booster</td>\n",
       "      <td>RFECV</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gradient Booster</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.960526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Feature Selection  Train Score  Test Score  CV Fold 1  \\\n",
       "0   Logistic Regression               PCA     0.947507    0.994681   0.935065   \n",
       "1   Logistic Regression             RFECV     0.971129    0.968085   0.974026   \n",
       "2   Logistic Regression     Random Forest     0.944882    0.984043   0.948052   \n",
       "3      Lasso Regression               PCA     0.947507    0.978723   0.948052   \n",
       "4      Lasso Regression             RFECV     0.960630    0.962766   0.935065   \n",
       "5      Lasso Regression     Random Forest     0.926509    0.952128   0.909091   \n",
       "6      Ridge Regression               PCA     0.950131    0.984043   0.935065   \n",
       "7      Ridge Regression             RFECV     0.944882    0.946809   0.909091   \n",
       "8      Ridge Regression     Random Forest     0.910761    0.952128   0.909091   \n",
       "9                   KNN               PCA     0.921260    0.973404   0.922078   \n",
       "10                  KNN             RFECV     0.926509    0.930851   0.896104   \n",
       "11                  KNN     Random Forest     0.913386    0.952128   0.922078   \n",
       "12                  SVC               PCA     1.000000    1.000000   0.623377   \n",
       "13                  SVC             RFECV     0.994751    1.000000   0.636364   \n",
       "14                  SVC     Random Forest     0.992126    0.994681   0.649351   \n",
       "15        Random Forest               PCA     1.000000    1.000000   0.935065   \n",
       "16        Random Forest             RFECV     0.994751    1.000000   0.961039   \n",
       "17        Random Forest     Random Forest     0.992126    1.000000   0.948052   \n",
       "18     Gradient Booster               PCA     1.000000    1.000000   0.987013   \n",
       "19     Gradient Booster             RFECV     1.000000    1.000000   0.948052   \n",
       "20     Gradient Booster     Random Forest     1.000000    1.000000   0.948052   \n",
       "\n",
       "    CV Fold 2  CV Fold 3  CV Fold 4  CV Fold 5  \n",
       "0    0.934211   0.973684   0.921053   0.921053  \n",
       "1    0.960526   0.960526   0.973684   0.921053  \n",
       "2    0.934211   0.934211   0.934211   0.921053  \n",
       "3    0.934211   0.973684   0.934211   0.907895  \n",
       "4    0.973684   0.986842   0.973684   0.881579  \n",
       "5    0.907895   0.921053   0.881579   0.881579  \n",
       "6    0.934211   0.973684   0.921053   0.921053  \n",
       "7    0.973684   0.986842   0.947368   0.907895  \n",
       "8    0.921053   0.907895   0.881579   0.894737  \n",
       "9    0.921053   0.934211   0.894737   0.921053  \n",
       "10   0.894737   0.973684   0.881579   0.881579  \n",
       "11   0.907895   0.894737   0.894737   0.881579  \n",
       "12   0.618421   0.618421   0.618421   0.618421  \n",
       "13   0.618421   0.644737   0.644737   0.644737  \n",
       "14   0.644737   0.671053   0.644737   0.644737  \n",
       "15   0.907895   0.907895   0.921053   0.921053  \n",
       "16   0.934211   0.960526   0.921053   0.947368  \n",
       "17   0.947368   0.921053   0.934211   0.947368  \n",
       "18   0.934211   0.947368   0.947368   0.894737  \n",
       "19   0.934211   0.947368   0.960526   0.921053  \n",
       "20   0.921053   0.921053   0.934211   0.960526  "
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Train Score'] = Train_Score\n",
    "results['Test Score'] = Test_Score\n",
    "results['CV Fold 1'] = fold1\n",
    "results['CV Fold 2'] = fold2\n",
    "results['CV Fold 3'] = fold3\n",
    "results['CV Fold 4'] = fold4\n",
    "results['CV Fold 5'] = fold5\n",
    "results.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>CV Fold 1</th>\n",
       "      <th>CV Fold 2</th>\n",
       "      <th>CV Fold 3</th>\n",
       "      <th>CV Fold 4</th>\n",
       "      <th>CV Fold 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.963755</td>\n",
       "      <td>0.979737</td>\n",
       "      <td>0.894249</td>\n",
       "      <td>0.888471</td>\n",
       "      <td>0.902882</td>\n",
       "      <td>0.884085</td>\n",
       "      <td>0.873434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032799</td>\n",
       "      <td>0.022354</td>\n",
       "      <td>0.110144</td>\n",
       "      <td>0.111230</td>\n",
       "      <td>0.111608</td>\n",
       "      <td>0.107430</td>\n",
       "      <td>0.101876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.910761</td>\n",
       "      <td>0.930851</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.618421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.962766</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.881579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.960630</td>\n",
       "      <td>0.984043</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.907895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.994751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.986842</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.960526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Train Score  Test Score  CV Fold 1  CV Fold 2  CV Fold 3  CV Fold 4  \\\n",
       "count    21.000000   21.000000  21.000000  21.000000  21.000000  21.000000   \n",
       "mean      0.963755    0.979737   0.894249   0.888471   0.902882   0.884085   \n",
       "std       0.032799    0.022354   0.110144   0.111230   0.111608   0.107430   \n",
       "min       0.910761    0.930851   0.623377   0.618421   0.618421   0.618421   \n",
       "25%       0.944882    0.962766   0.909091   0.907895   0.907895   0.881579   \n",
       "50%       0.960630    0.984043   0.935065   0.934211   0.934211   0.921053   \n",
       "75%       0.994751    1.000000   0.948052   0.934211   0.973684   0.934211   \n",
       "max       1.000000    1.000000   0.987013   0.973684   0.986842   0.973684   \n",
       "\n",
       "       CV Fold 5  \n",
       "count  21.000000  \n",
       "mean    0.873434  \n",
       "std     0.101876  \n",
       "min     0.618421  \n",
       "25%     0.881579  \n",
       "50%     0.907895  \n",
       "75%     0.921053  \n",
       "max     0.960526  "
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC, Random Forest, and Gradient Booster all overfit the model, with SVC the worst offender with the lowest Cross Validation Scores across the board. KNN also showed signs of overfitting. \n",
    "\n",
    "Logistic Regression Models (including Lasso and Ridge) showed the most consistent results with PCA. Of these, Lasso performed slightly better than the other two models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
